{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dir\n",
    "input_dir = '/home/andrew/Downloads/slack_data/Testing Export UL Slack export May 22 2021 - Nov 21 2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of files\n",
    "\n",
    "int_logs = pd.DataFrame()\n",
    "channels = pd.DataFrame()\n",
    "users    = pd.DataFrame()\n",
    "messages = list()\n",
    "\n",
    "for root, dirs, files in os.walk(input_dir, topdown=True):\n",
    "\n",
    "  # these are the conf/user info files, specified at root of export\n",
    "  if root == input_dir:\n",
    "    for file in files:\n",
    "\n",
    "      path = os.path.join(root, file)\n",
    "\n",
    "      # channels.json\n",
    "      if file == 'channels.json':\n",
    "        data = json.load(open(path, encoding='utf-8'))\n",
    "        channels = pd.json_normalize(data)\n",
    "\n",
    "      if file == 'users.json':\n",
    "        data = json.load(open(path, encoding='utf-8'))\n",
    "        users = pd.json_normalize(data)\n",
    "\n",
    "  # the rest are channels with n files by date\n",
    "  # read each file and append dataframe to a list for concatenation\n",
    "  else:\n",
    "    for file in files:\n",
    "\n",
    "      path = os.path.join(root, file)\n",
    "\n",
    "      data = json.load(open(path, encoding='utf-8'))\n",
    "\n",
    "      df = pd.json_normalize(data)\n",
    "\n",
    "      # adds a column to get channel name\n",
    "      df['channel_name'] = os.path.basename(root)\n",
    "\n",
    "      messages.append(df)\n",
    "\n",
    "# concat all read messages into one frame\n",
    "df = pd.concat(messages, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert timestamps to relativity loadable\n",
    "def to_rel_datetime(series):\n",
    "  '''\n",
    "  Returns datetime from timestamp seconds as MM/DD/YYYY HH:MM:SS (24 hour format)\n",
    "  Implicitly handles null values in the series.\n",
    "  \n",
    "  @params: pandas series of timestamp values\n",
    "  '''\n",
    "  return pd.to_datetime(series, unit='s').dt.strftime('%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "# need to convert these columns into rel readable\n",
    "ts_cols = ['ts', 'thread_ts']\n",
    "\n",
    "for col in ts_cols:\n",
    "  df[col + '_converted'] = to_rel_datetime(df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to expand some nested json structures and prefix their column names\n",
    "# reactions, attachments\n",
    "def unnest(df, cols):\n",
    "    '''\n",
    "    For each passed column in passed dataframe, filters out NaN values\n",
    "    Explodes the list of dictionaries and creates a new series from the exposed dicts\n",
    "    Adds a prefix to their column of \"<COLUMN_NAME> + '.'\" (ex. reactions.user)\n",
    "\n",
    "    @Params: dataframe, dataframe column(s)\n",
    "\n",
    "    Returns a dataframe\n",
    "    '''\n",
    "    for col in cols:\n",
    "        nfilter = (df[col].notnull())\n",
    "        df = df.join(df.loc[nfilter, col].explode(0).apply(pd.Series).add_prefix(str(col) + '.'))\n",
    "    return df\n",
    "\n",
    "df = unnest(df, ['reactions', 'attachments'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all users in each channel, active or otherwise.\n",
    "# these are sitting on the channels table in the 'members' column\n",
    "channel_members = channels[['name', 'members']].copy()\n",
    "df = df.merge(channel_members, left_on='channel_name', right_on='name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the 'text' column of the data, want to replace user ID with real name\n",
    "pattr = re.compile(r'<@(.*)>')\n",
    "def repl_user_name(cell, user_table, pattr):\n",
    "  '''\n",
    "  Function queries the user table by ID and returns that users profile.realname\n",
    "  Does so with regular expressions as we want to surgically change text in a string\n",
    "\n",
    "  @Params: cell to operate on, dataframe of user information, regex pattern to search\n",
    "  '''\n",
    "\n",
    "  # take string and place id(s) in variable\n",
    "  matches = re.findall(pattr, cell)\n",
    "\n",
    "  for match in matches:\n",
    "    repl = user_table.loc[user_table['id'] == match, 'profile.real_name'].values[0]\n",
    "    cell = re.sub(pattr, repl, cell)\n",
    "\n",
    "  return cell\n",
    "\n",
    "df['text_changed'] = df['text'].apply(\n",
    "  lambda cell: repl_user_name(cell, users, pattr)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfe = df[['text', 'text_changed']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a field of date prepending channel name\n",
    "# will use to group this into 24/hour periods later"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1cff50607d090b690574ec349be9bf71cfbdb2bb2404a0072778607bd003c9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
